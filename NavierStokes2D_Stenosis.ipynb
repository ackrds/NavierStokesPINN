{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35rbaVMHOB8K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch \n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import scipy.interpolate\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import sys\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import csv\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
        "from math import exp, sqrt, pi\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data = scipy.io.loadmat(r\"/content/gdrive/MyDrive/Research/RaissiData/Stenosis2D.mat\") \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vN_4D4JV-mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_n = 128\n",
        "input_n = 12\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self, inplace=True):\n",
        "        super(Swish, self).__init__()\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x, ):\n",
        "      x = x.mul_(torch.sigmoid(x))\n",
        "\n",
        "      return x\n",
        "\n",
        "\n",
        "class PINet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PINet, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "                    nn.Linear(input_n,h_n), \n",
        "                    Swish(),\n",
        "                    nn.Linear(h_n,h_n),\n",
        "                    Swish(),\n",
        "                    nn.Linear(h_n,h_n),\n",
        "                    Swish(),\n",
        "                    nn.Linear(h_n,h_n),\n",
        "                    Swish(),\n",
        "                    nn.Linear(h_n,h_n),\n",
        "                    Swish(),\n",
        "\n",
        "\n",
        "                    nn.Linear(h_n,1),\n",
        "                    \n",
        "                )\n",
        "\n",
        "    def forward(self,x):\t\n",
        "        output = self.main(x)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "CkqdDWitH2kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Loss_data(xd,yd,ud,vd,pd,cd,u_target,v_target,p_target,c_target):\n",
        "\n",
        "    net_in_u = torch.cat((ud, xd, yd), 1)\n",
        "    net_in_v = torch.cat((vd, xd, yd), 1)\n",
        "    net_in_p = torch.cat((pd, xd, yd), 1)\n",
        "    net_in_c = torch.cat((cd, xd, yd), 1)\n",
        "\n",
        "\n",
        "    out1_u = net2_u(net_in_u)\n",
        "    out1_v = net2_v(net_in_v)\n",
        "    out1_p = net2_p(net_in_p)\n",
        "    out1_c = net2_c(net_in_c)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    out1_u = out1_u.view(len(out1_u), -1)\n",
        "    out1_v = out1_v.view(len(out1_v), -1)\n",
        "    out1_p = out1_p.view(len(out1_p), -1)\n",
        "    out1_c = out1_c.view(len(out1_c), -1)\n",
        "\n",
        "    loss_fun = nn.MSELoss()\n",
        "\n",
        "    loss_d =  loss_fun(out1_u, u_target) + loss_fun(out1_v, v_target) + loss_fun(out1_p, p_target) + loss_fun(out1_c, c_target)\n",
        "            \n",
        "    return loss_d\n",
        "\n",
        "def criterion(u_in, v_in, p_in, c_in, x,  y):\n",
        "\n",
        "    Re = 5\n",
        "    Pec = 15\n",
        "    \n",
        "    x = torch.tensor(x).to(device)\n",
        "    y = torch.tensor(y).to(device) \n",
        "            \n",
        "    x.requires_grad = True\n",
        "    y.requires_grad = True\n",
        "      \n",
        "    net_in_u = torch.cat((u_in, x, y),1)\n",
        "    net_in_v = torch.cat((v_in, x, y),1)\n",
        "    net_in_p = torch.cat((p_in, x, y),1)\n",
        "    net_in_c = torch.cat((c_in, x, y),1)\n",
        "\n",
        "    u = net2_u(net_in_u)\n",
        "    u = u.view(len(u),-1)\n",
        "\n",
        "    v = net2_v(net_in_v)\n",
        "    v = v.view(len(v),-1)\n",
        "\n",
        "    P = net2_p(net_in_p)\n",
        "    P = P.view(len(P),-1)\n",
        "\n",
        "    c = net2_c(net_in_c)\n",
        "    c = c.view(len(c),-1)\n",
        "    \n",
        "    \n",
        "    u_x = torch.autograd.grad(u,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "    u_xx = torch.autograd.grad(u_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "\n",
        "    u_y = torch.autograd.grad(u,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "    u_yy = torch.autograd.grad(u_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "\n",
        "    v_x = torch.autograd.grad(v,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "    v_xx = torch.autograd.grad(v_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "\n",
        "    v_y = torch.autograd.grad(v,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "    v_yy = torch.autograd.grad(v_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "\n",
        "    c_x = torch.autograd.grad(c,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "    c_xx = torch.autograd.grad(c_x,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "\n",
        "    c_y = torch.autograd.grad(c,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "    c_yy = torch.autograd.grad(c_y,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "    \n",
        "    \n",
        "    P_x = torch.autograd.grad(P,x,grad_outputs=torch.ones_like(x),create_graph = True,only_inputs=True)[0]\n",
        "    P_y = torch.autograd.grad(P,y,grad_outputs=torch.ones_like(y),create_graph = True,only_inputs=True)[0]\n",
        "                    \n",
        "    loss_1 = u*u_x + v*u_y - (Re^-1)*(u_xx + u_yy) + P_x\n",
        "    loss_2 = u*v_x + v*v_y - (Re^-1)*(v_xx+  v_yy) + P_y\n",
        "    loss_3 = u*c_x + v*c_y - (Pec^-1)*(c_xx+  c_yy) \n",
        "    loss_4 = u_x  + v_y \n",
        "    \n",
        "    loss_f1 = nn.MSELoss()\n",
        "    \n",
        "    loss = loss_f1(loss_1,torch.zeros_like(loss_1))+  loss_f1(loss_2,torch.zeros_like(loss_2))+  loss_f1(loss_3,torch.zeros_like(loss_3))\n",
        "    \n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cFT1SgRT8_oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(u_in, v_in, p_in, c_in, x_in, y_in,\n",
        "                u_data, v_data, p_data, c_data, x_data, y_data,\n",
        "                u_target, v_target, p_target, c_target):\n",
        "      \n",
        "    x  = torch.Tensor(x_in).to(device)\n",
        "    y  = torch.Tensor(y_in).to(device)\n",
        "\n",
        "    u_in = torch.Tensor(u_in).to(device).squeeze()\n",
        "    v_in = torch.Tensor(v_in).to(device).squeeze()\n",
        "    p_in = torch.Tensor(p_in).to(device).squeeze()\n",
        "    c_in = torch.Tensor(c_in).to(device).squeeze()\n",
        "\n",
        "\n",
        "    x_data = torch.Tensor(x_data).to(device)\n",
        "    y_data = torch.Tensor(y_data).to(device)\n",
        "\n",
        "    u_data = torch.Tensor(u_data).to(device).squeeze()\n",
        "    v_data = torch.Tensor(v_data).to(device).squeeze()\n",
        "    p_data = torch.Tensor(p_data).to(device).squeeze()\n",
        "    c_data = torch.Tensor(c_data).to(device).squeeze()\n",
        "    \n",
        "    u_target = torch.Tensor(u_target).to(device)\n",
        "    v_target = torch.Tensor(v_target).to(device)\n",
        "    p_target = torch.Tensor(p_target).to(device)\n",
        "    c_target = torch.Tensor(c_target).to(device)\n",
        "\n",
        "        \n",
        "    loss_dict = []\n",
        "              \n",
        "    net2_u.zero_grad()\n",
        "    net2_v.zero_grad()\n",
        "    net2_p.zero_grad()\n",
        "    net2_c.zero_grad()\n",
        "\n",
        "    loss_eqn  = criterion(u_in, v_in, p_in, c_in, x, y)\n",
        "    loss_data = Loss_data(x_data, y_data, u_data, v_data, p_data, c_data, u_target, v_target, p_target, c_target)\n",
        "\n",
        "    loss = loss_eqn + loss_data \n",
        "    \n",
        "    loss_dict.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer_u.step() \n",
        "    optimizer_v.step()\n",
        "    optimizer_p.step()  \n",
        "    optimizer_c.step() \n",
        "\n",
        "    net_in_u = torch.cat((u_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "    net_in_v = torch.cat((v_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "    net_in_p = torch.cat((p_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "\n",
        "\n",
        "    output_u = net2_u(net_in_u) \n",
        "    output_v = net2_v(net_in_v)  \n",
        "    output_p = net2_p(net_in_p)\n",
        "\n",
        "    \n",
        "    # output_u = output_u.cpu().data.numpy() \n",
        "    # output_v = output_v.cpu().data.numpy()\n",
        "    # output_p = output_p.cpu().data.numpy()\n",
        "    \n",
        "    return output_u.clone().detach().cpu().data.numpy() , output_v.clone().detach().cpu().data.numpy() , output_p.clone().detach().cpu().data.numpy() , loss_dict"
      ],
      "metadata": {
        "id": "ZvvX6qn6rDEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_epoch(u_in, v_in, p_in, c_in, x_in, y_in, \n",
        "              u_data, v_data, p_data, c_data, x_data, y_data,\n",
        "              u_target, v_target, p_target, c_target): \n",
        "    \n",
        "    u_in = torch.Tensor(u_in).to(device).squeeze()\n",
        "    v_in = torch.Tensor(v_in).to(device).squeeze()\n",
        "    p_in = torch.Tensor(p_in).to(device).squeeze()\n",
        "    c_in = torch.Tensor(c_in).to(device).squeeze()\n",
        "\n",
        "    x  = torch.Tensor(x_in).to(device)\n",
        "    y  = torch.Tensor(y_in).to(device)\n",
        "\n",
        "    u_data = torch.Tensor(u_data).to(device).squeeze()\n",
        "    v_data = torch.Tensor(v_data).to(device).squeeze()\n",
        "    p_data = torch.Tensor(p_data).to(device).squeeze()\n",
        "    c_data = torch.Tensor(c_data).to(device).squeeze()\n",
        "\n",
        "    \n",
        "    x_data = torch.Tensor(x_data).to(device)\n",
        "    y_data = torch.Tensor(y_data).to(device)\n",
        "\n",
        "    u_target = torch.Tensor(u_target).to(device)\n",
        "    v_target = torch.Tensor(v_target).to(device)\n",
        "    p_target = torch.Tensor(p_target).to(device)  \n",
        "    c_target = torch.Tensor(c_target).to(device)  \n",
        "\n",
        "\n",
        "    loss_dict = []      \n",
        "    \n",
        "    loss_eqn  = criterion(u_in, v_in, p_in, c_in, x, y)\n",
        "    loss_data = Loss_data(x_data, y_data, u_data, v_data, p_data, c_data, u_target, v_target, p_target, c_target)\n",
        "\n",
        "    loss = loss_eqn + loss_data\n",
        "    \n",
        "    loss_dict.append(loss.item())\n",
        "\n",
        "    net_in_u = torch.cat((u_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "    net_in_v = torch.cat((v_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "    net_in_p = torch.cat((p_in,x.requires_grad_(),y.requires_grad_()),1)\n",
        "\n",
        "\n",
        "    output_u = net2_u(net_in_u) \n",
        "    output_v = net2_v(net_in_v)  \n",
        "    output_p = net2_p(net_in_p)\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    return output_u.clone().detach().cpu().data.numpy() , output_v.clone().detach().cpu().data.numpy() , output_p.clone().detach().cpu().data.numpy() , loss_dict"
      ],
      "metadata": {
        "id": "E9tuRRzSrHBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 5e-4 \n",
        "step_epoch = 1200\n",
        "decay_rate = 0.1 \n",
        "Diff = 0.00125 \n",
        "rho = 1.\n",
        "lamda_rate = 1e-6\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net2_u = PINet().to(device)\n",
        "net2_v = PINet().to(device)\n",
        "net2_p = PINet().to(device)\n",
        "net2_c = PINet().to(device)\n",
        "\n",
        "\n",
        "\n",
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "\n",
        "net2_u.apply(init_normal)\n",
        "net2_v.apply(init_normal)\n",
        "net2_p.apply(init_normal)\n",
        "net2_c.apply(init_normal)\n",
        "\n",
        "\n",
        "optimizer_u = optim.Adam(net2_u.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
        "optimizer_v = optim.Adam(net2_v.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
        "optimizer_p = optim.Adam(net2_p.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
        "optimizer_c = optim.Adam(net2_c.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
        "\n",
        "\n",
        "scheduler_u = torch.optim.lr_scheduler.StepLR(optimizer_u, step_size=step_epoch, gamma=decay_rate)\n",
        "scheduler_v = torch.optim.lr_scheduler.StepLR(optimizer_v, step_size=step_epoch, gamma=decay_rate)\n",
        "scheduler_p = torch.optim.lr_scheduler.StepLR(optimizer_p, step_size=step_epoch, gamma=decay_rate)\n",
        "scheduler_c = torch.optim.lr_scheduler.StepLR(optimizer_c, step_size=step_epoch, gamma=decay_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "CA5a4Jqc4FMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_channel(ch):\n",
        "  mean = np.mean(ch[:])\n",
        "  std  = np.std(ch[:]) \n",
        "\n",
        "  ch[:] -= mean\n",
        "  ch[:] /= std\n",
        "  return ch\n"
      ],
      "metadata": {
        "id": "fv6I1GWfgAIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkK2UlsTbAA1"
      },
      "outputs": [],
      "source": [
        "epochs  = 100\n",
        "\n",
        "x = data['x_star']\n",
        "y = data['y_star']\n",
        "\n",
        "u = data['U_star']\n",
        "v = 400*data['V_star']\n",
        "p = data['P_star']\n",
        "c = data['C_star']\n",
        "\n",
        "\n",
        "Nt = u.shape[1]\n",
        "\n",
        "idx = np.where(x == x.max())[0][-1]\n",
        "\n",
        "x = x[:idx]\n",
        "y = y[:idx]\n",
        "\n",
        "u = u[:idx,:]\n",
        "v = v[:idx,:]\n",
        "p = p[:idx,:]\n",
        "c = c[:idx,:]\n",
        "\n",
        "u_min = u.min()\n",
        "v_min = v.min()\n",
        "p_min = p.min()\n",
        "\n",
        "u_max = u.max()\n",
        "v_max = v.max()\n",
        "p_max = p.max()\n",
        "\n",
        "N = x.shape[0]\n",
        "\n",
        "train_index = 30\n",
        "val_index = 35\n",
        "test_index = 70\n",
        "\n",
        "train_range = np.arange(0, train_index)\n",
        "val_range  = np.arange(train_index, val_index)\n",
        "test_range = np.arange(val_index, test_index)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "min_val_loss = 1e10\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  train_epoch_loss = []\n",
        "  start = time.time()\n",
        "  \n",
        "  scheduler_u.step()\n",
        "  scheduler_v.step()\n",
        "  scheduler_p.step()\n",
        "  scheduler_c.step()\n",
        "\n",
        "\n",
        "  for i in train_range:\n",
        "      # Input data for previous snapshots\n",
        "\n",
        "      u_in = u[:,i:i+10]\n",
        "      v_in = v[:,i:i+10]\n",
        "      p_in = p[:,i:i+10]\n",
        "      c_in = c[:,i:i+10]\n",
        "\n",
        "\n",
        "      u_target = u[:,i+15:i+16]\n",
        "      v_target = v[:,i+15:i+16]\n",
        "      p_target = p[:,i+15:i+16]\n",
        "      c_target = c[:,i+15:i+16]\n",
        "\n",
        "      # Data from final snapshot\n",
        "\n",
        "      rand_idx = np.random.choice(N, 10000)\n",
        "\n",
        "      x_data_in = x[rand_idx,:]\n",
        "      y_data_in = y[rand_idx,:]\n",
        "\n",
        "      u_data_in = u_in[rand_idx,:]\n",
        "      v_data_in = v_in[rand_idx,:]\n",
        "      p_data_in = p_in[rand_idx,:]\n",
        "      c_data_in = c_in[rand_idx,:]\n",
        "\n",
        "\n",
        "      u_data_target = u_target[rand_idx,:]\n",
        "      v_data_target = v_target[rand_idx,:]\n",
        "      p_data_target = p_target[rand_idx,:]\n",
        "      c_data_target = c_target[rand_idx,:]\n",
        "\n",
        "\n",
        "\n",
        "      u_star, v_star, p_star, _  = train_epoch(u_in, v_in, p_in, c_in, x, y,\n",
        "                                               u_data_in, v_data_in, p_data_in, c_data_in, x_data_in, y_data_in,\n",
        "                                                u_data_target,v_data_target,p_data_target, c_data_target)\n",
        "      \n",
        "      \n",
        "      mse_loss = mean_squared_error(u_target, u_star) + mean_squared_error(v_target, v_star) + mean_squared_error(p_target, p_star)\n",
        "      train_epoch_loss.append(np.mean(mse_loss))\n",
        "  \n",
        "   \n",
        "  \n",
        "  end = time.time()\n",
        "  print(f'Epoch: {epoch}, Loss: {np.mean(train_epoch_loss)}, Time: {end-start}')\n",
        "  train_losses.append(np.mean(train_epoch_loss))\n",
        "    \n",
        "  if epoch % 5 == 0:\n",
        "      \n",
        "      val_epoch_mse_loss = []\n",
        "      val_epoch_percentage_loss = []\n",
        "      for i in val_range:\n",
        "\n",
        "        u_in = u[:,i:i+10]\n",
        "        v_in = v[:,i:i+10]\n",
        "        p_in = p[:,i:i+10]\n",
        "        c_in = c[:,i:i+10]\n",
        "\n",
        "        u_target = u[:,i+15:i+16]\n",
        "        v_target = v[:,i+15:i+16]\n",
        "        p_target = p[:,i+15:i+16]\n",
        "        c_target = c[:,i+15:i+16]\n",
        "\n",
        "\n",
        "        rand_idx = np.random.choice(N, 10000)\n",
        "\n",
        "        x_data_in = x[rand_idx,:]\n",
        "        y_data_in = y[rand_idx,:]\n",
        "\n",
        "        u_data_in = u_in[rand_idx,:]\n",
        "        v_data_in = v_in[rand_idx,:]\n",
        "        p_data_in = p_in[rand_idx,:]\n",
        "        c_data_in = c_in[rand_idx,:]\n",
        "\n",
        "\n",
        "        u_data_target = u_target[rand_idx,:]\n",
        "        v_data_target = v_target[rand_idx,:]\n",
        "        p_data_target = p_target[rand_idx,:]\n",
        "        c_data_target = c_target[rand_idx,:]\n",
        "\n",
        "        u_star, v_star, p_star, _  = val_epoch(u_in, v_in, p_in, c_in, x, y, \n",
        "                                                  u_data_in, v_data_in, p_data_in, c_data_in, x_data_in, y_data_in,\n",
        "                                                  u_data_target, v_data_target, p_data_target, c_data_target) \n",
        "        \n",
        "        \n",
        "        mse_loss = mean_squared_error(u_target, u_star) + mean_squared_error(v_target, v_star) + mean_squared_error(p_target, p_star)\n",
        "        print(np.mean(u_star), np.mean(u_target), np.mean(v_star), np.mean(v_target), np.mean(p_star), np.mean(p_target))        \n",
        "\n",
        "        val_epoch_mse_loss.append(np.mean(mse_loss))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = u_target , vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "      plt.title('Real results, u')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = v_target ,vmin=v_min, vmax=v_max, cmap = 'rainbow')\n",
        "      plt.title('Real results, v')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = p_target ,vmin=p_min, vmax=p_max, cmap = 'rainbow')\n",
        "      plt.title('Real results, p')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      \n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = u_star ,vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "      plt.title('NN results, u')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = v_star , vmin=v_min, vmax=v_max, cmap = 'rainbow')\n",
        "      plt.title('NN results, v')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "      \n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = p_star , vmin=p_min, vmax=p_max,cmap = 'rainbow')\n",
        "      plt.title('NN results, p')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "      \n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c =abs(u_star-u_target),vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "      plt.title('Absolute error, u')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = abs(v_star-v_target) , vmin=v_min, vmax=v_max,cmap = 'rainbow')\n",
        "      plt.title('Absolute error, v')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      plt.figure()\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.scatter(x, y, c = abs(p_star-p_target) , vmin=p_min, vmax=p_max,cmap = 'rainbow')\n",
        "      plt.title('Absolute error, p')\n",
        "      plt.colorbar()\n",
        "      plt.show()\n",
        "\n",
        "      print('Validation MSE Loss: ', np.mean(val_epoch_mse_loss),'Validation Percentage Loss: ', np.mean(val_epoch_percentage_loss) )\n",
        "      val_losses.append(np.mean(val_epoch_mse_loss))\n",
        "      if val_losses[-1] < min_val_loss:\n",
        "        min_val_loss = val_losses[-1]\n",
        "        best_model = (net2_u.state_dict(), net2_v.state_dict(), net2_p.state_dict())\n",
        "\n",
        "\n",
        "# torch.save(best_model[0].state_dict(), \"/content/gdrive/MyDrive/Research/BestU\")\n",
        "# torch.save(best_model[1].state_dict(), \"/content/gdrive/MyDrive/Research/BestV\")\n",
        "# torch.save(best_model[2].state_dict(), \"/content/gdrive/MyDrive/Research/BestP\")\n",
        "\n",
        "\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(val_losses)"
      ],
      "metadata": {
        "id": "NS9lsWeSBqXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2_u = PINet().to(device)\n",
        "net2_v = PINet().to(device)\n",
        "net2_p = PINet().to(device)\n",
        "\n",
        "net2_u.load_state_dict(best_model[0])\n",
        "net2_v.load_state_dict(best_model[1])\n",
        "net2_p.load_state_dict(best_model[2])\n",
        "\n",
        "\n",
        "\n",
        "test_loss = []\n",
        "for i in test_range:\n",
        "\n",
        "    u_in = u[:,i:i+10]\n",
        "    v_in = v[:,i:i+10]\n",
        "    p_in = p[:,i:i+10]\n",
        "\n",
        "    u_target = u[:,i+15:i+16]\n",
        "    v_target = v[:,i+15:i+16]\n",
        "    p_target = p[:,i+15:i+16]\n",
        "\n",
        "    # Data from final snapshot\n",
        "\n",
        "    rand_idx = np.random.choice(N, 10000)\n",
        "\n",
        "    x_data_in = x[rand_idx,:]\n",
        "    y_data_in = y[rand_idx,:]\n",
        "\n",
        "    u_data_in = u_in[rand_idx,:]\n",
        "    v_data_in = v_in[rand_idx,:]\n",
        "    p_data_in = p_in[rand_idx,:]\n",
        "\n",
        "    u_data_target = u_target[rand_idx,:]\n",
        "    v_data_target = v_target[rand_idx,:]\n",
        "    p_data_target = p_target[rand_idx,:]\n",
        "\n",
        "    u_star, v_star, p_star, _  = val_epoch(u_in, v_in, p_in, c_in, x, y, \n",
        "                                                  u_data_in, v_data_in, p_data_in, c_data_in, x_data_in, y_data_in,\n",
        "                                                  u_data_target, v_data_target, p_data_target, c_data_target)\n",
        "    \n",
        "    \n",
        "    mse_loss = mean_squared_error(u_target, u_star) + mean_squared_error(v_target, v_star) + mean_squared_error(p_target, p_star)\n",
        "    test_loss.append(np.mean(mse_loss))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = u_target , vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "    plt.title('Real results, u')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = v_target ,vmin=v_min, vmax=v_max, cmap = 'rainbow')\n",
        "    plt.title('Real results, v')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = p_target ,vmin=p_min, vmax=p_max, cmap = 'rainbow')\n",
        "    plt.title('Real results, p')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = u_star ,vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "    plt.title('NN results, u')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = v_star , vmin=v_min, vmax=v_max, cmap = 'rainbow')\n",
        "    plt.title('NN results, v')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = p_star , vmin=p_min, vmax=p_max,cmap = 'rainbow')\n",
        "    plt.title('NN results, p')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c =abs(u_star-u_target),vmin=u_min, vmax=u_max, cmap = 'rainbow')\n",
        "    plt.title('Absolute error, u')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = abs(v_star-v_target) , vmin=v_min, vmax=v_max,cmap = 'rainbow')\n",
        "    plt.title('Absolute error, v')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.scatter(x, y, c = abs(p_star-p_target) , vmin=p_min, vmax=p_max,cmap = 'rainbow')\n",
        "    plt.title('Absolute error, p')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    print('Test Loss: ', np.mean(test_loss))\n"
      ],
      "metadata": {
        "id": "Y5-n38FTZB4s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}